// Package snippet implements the Merger class to retrieve and merge
// secondary and primary snippets, and to publish the merged snippets.
package snippet

import (
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"strings"

	"gapi-cmds/src/common/errorlist"
	"gapi-cmds/src/common/gcs"
	"gapi-cmds/src/snippetgen/common/fragment"
)

// fragmentMap indexes fragments by their unique key, which includes the method ID and the API version.
type fragmentMap map[fragment.Key]*fragment.Info

// Merger performs a merge between primary and secondary fragments to
// come up with the merged fragments that will be shown to users. It
// can work on purely local directories, or fetch and publish to
// Google Cloud Storage.
//
// Errors are not directly returned from the public methods, but are
// instead accumulated internally. They may be checked at any time by
// calling the Error() method on Merger. This allows multiple errors
// to be reported at once.
type Merger struct {
	// The specified locations for the primary, secondary, and
	// merged (merged) fragments.
	primaryLocation   string
	secondaryLocation string
	mergedLocation    string

	// The local working directories for the primary, secondary,
	// and merged fragments. These directories are not cleaned up
	// in any way, to allow for inspection after this tool runs.
	primaryDirectory   string
	secondaryDirectory string
	mergedDirectory    string

	// gcs is the interface to Google Cloud Storage.
	gcs *gcs.GCS

	// tmpDir is the temporary directory, should we need one.
	tmpDir string

	// The various fragments, indexed by their ID and API version
	primaryFragments   fragmentMap
	secondaryFragments fragmentMap
	mergedFragments    fragmentMap

	// errorlist is a list of accumulated errors, so that we can
	// show several to the user at once.
	errorList errorlist.Errors
}

// Init initializes the Merger object with the provided 'gsutilPath'
// to the "gsutil" utility, and the locations of the primary,
// secondary, and merged fragments. Any errors are accumulated and can
// be checked with Error().
func (mrg *Merger) Init(gsutilPath string, primaryLocation, secondaryLocation, mergedLocation string) {
	var err error
	if mrg.gcs, err = gcs.New(gsutilPath); err != nil {
		mrg.errorList.Add(err)
	}

	mrg.primaryLocation = primaryLocation
	mrg.secondaryLocation = secondaryLocation
	mrg.mergedLocation = mergedLocation
	if err = mrg.createDirectories(); err != nil {
		mrg.errorList.Add(err)
	}
}

// createDirectories creates the local primary, secondary, and merged directories that will be used for merging fragments.
func (mrg *Merger) createDirectories() error {
	primaryDirectory, err := mrg.prepareDirectory("primary", mrg.primaryLocation, false)
	if err != nil {
		return err
	}
	secondaryDirectory, err := mrg.prepareDirectory("secondary", mrg.secondaryLocation, false)
	if err != nil {
		return err
	}
	mergedDirectory, err := mrg.prepareDirectory("merged", mrg.mergedLocation, true)
	if err != nil {
		return err
	}

	mrg.primaryDirectory = primaryDirectory
	mrg.secondaryDirectory = secondaryDirectory
	mrg.mergedDirectory = mergedDirectory

	return nil
}

// prepareDirectory creates a local temporary directory 'name' if the
// 'requested' location refers to GCS (rather than already being a
// local directory) or if 'createIfLocal' is set. It returns the name
// of the local directory (either the new one created or the one
// specified by 'requested').
func (mrg *Merger) prepareDirectory(name, requested string, createIfLocal bool) (string, error) {
	if strings.HasPrefix(requested, gcs.BucketPrefix) {
		if len(mrg.tmpDir) == 0 {
			tmpDir, err := ioutil.TempDir("", "snippetgen")
			if err != nil {
				return "", fmt.Errorf("error creating tempdir name: %s", err)
			}
			mrg.tmpDir = tmpDir
			log.Printf("created tmpDir=%q", tmpDir)
		}
		requested = filepath.Join(mrg.tmpDir, name)
		createIfLocal = true
	}

	if createIfLocal {
		if err := os.MkdirAll(requested, os.ModePerm); err != nil {
			return "", fmt.Errorf("error creating tempdir: %s", err)
		}
	} else {
		if _, err := os.Stat(requested); err != nil {
			return "", fmt.Errorf("could not stat directory %q: %q: %s", name, requested, err)
		}
	}

	return requested, nil
}

// GetFragments obtains and reads the fragments from the primary and
// secondary locations. Failures are accumulated and can be checked via Error().
func (mrg *Merger) GetFragments() {
	mrg.pullSources()
	mrg.readFragments()
}

// pullSources retrieves the primary and secondary fragments from GCS
// to local directories if needed. It does nothing if the primary and
// secondary locations already refer to lcoal directories.
func (mrg *Merger) pullSources() {
	if strings.HasPrefix(mrg.primaryLocation, gcs.BucketPrefix) {
		mrg.transferWithGCS(mrg.primaryLocation, mrg.primaryDirectory)
	}

	if strings.HasPrefix(mrg.secondaryLocation, gcs.BucketPrefix) {
		mrg.transferWithGCS(mrg.secondaryLocation, mrg.secondaryDirectory)
	}
}

// readFragments reads the primary and secondary fragments from the
// appropriate local directories.
func (mrg *Merger) readFragments() {
	var err error
	mrg.primaryFragments, err = readFragmentsFrom(mrg.primaryDirectory)
	if err != nil {
		mrg.errorList.Add(err)
	}
	log.Printf("read %d primary fragments from %q", len(mrg.primaryFragments), mrg.primaryDirectory)

	mrg.secondaryFragments, err = readFragmentsFrom(mrg.secondaryDirectory)
	if err != nil {
		mrg.errorList.Add(err)
	}

	log.Printf("read %d secondary fragments from %q", len(mrg.secondaryFragments), mrg.secondaryDirectory)
}

// readFragmentsFrom reads all the fragment files under 'directory'
// into a fragmentMap that it returns.
func readFragmentsFrom(directory string) (fragmentMap, error) {
	readFragments := make(fragmentMap)
	errorList := errorlist.Errors{}

	walkFn := func(path string, info os.FileInfo, err error) error {
		if err != nil {
			errorList.Add(fmt.Errorf("stopping processing of %q due to error at %q: %s", directory, path, err))
			return err
		}

		if info.IsDir() {
			return nil
		}

		fragmentInfo, err := fragment.FromFile(path)
		if err != nil {
			// record error but continue processing files
			errorList.Add(err)
			return nil
		}

		if !fragmentInfo.HasConsistentMetadata() {
			// record error but continue processing files
			errorList.Add(fmt.Errorf("contents of file %q not consistent with its path", path))
			return nil
		}

		// If we have multiple revisions, use the latest one.
		key := fragmentInfo.Key()
		if previous, ok := readFragments[key]; !ok || fragmentInfo.ApiRevision() > previous.ApiRevision() {
			readFragments[key] = fragmentInfo
		}
		return nil
	}

	if err := filepath.Walk(directory, walkFn); err != nil {
		return nil, fmt.Errorf("error reading snippets under %q: %s\n%s", directory, err, errorList.Error())
	}

	return readFragments, errorList.Error()
}

// MergeFragments merges the primary and secondary fragments, writes them to the appropriate local directory, and performs a basic validity check. Failures in any of these steps are accumulated and can be checked via Error().
func (mrg *Merger) MergeFragments() {
	mrg.computeMergedFragments()
	mrg.writeMergedFragments()
	mrg.validateMergedFragments()
}

// computeMergedFragments merges the fragments in mrg.primaryFragments
// and mrg.secondaryFragments. The former always takes precedence.
func (mrg *Merger) computeMergedFragments() {
	mrg.mergedFragments = make(fragmentMap)
	for key, file := range mrg.primaryFragments {
		log.Printf("merging %q\n", key)
		mergedFile, err := file.MergeWith(mrg.secondaryFragments[key])
		if err != nil {
			mrg.errorList.Add(fmt.Errorf("error merging %q: %s", key, err))
			continue
		}
		mrg.mergedFragments[mergedFile.Key()] = mergedFile
	}

	for key, file := range mrg.secondaryFragments {
		if !file.Processed {
			log.Printf("adding %q\n", key)
			mrg.mergedFragments[key] = file
		}
	}
}

// writeMergedFragments writes the merged fragments into the
// appropriate working directories: once with the provided revision
// number in the path, and once with the "current" revision number
// sentinel in the path.
func (mrg *Merger) writeMergedFragments() {
	for key, file := range mrg.mergedFragments {
		if err := file.ToFile(mrg.mergedDirectory, false); err != nil {
			mrg.errorList.Add(fmt.Errorf("error writing file for %q: %s", key, err))
		}
		if err := file.ToFile(mrg.mergedDirectory, true); err != nil {
			mrg.errorList.Add(fmt.Errorf("error writing file for %q: %s", key, err))
		}
	}
}

// validateMergedFragments performs basic integrity checks on the
// fragments, accumulating any failures so that they may be retrieved
// via Error().
func (mrg *Merger) validateMergedFragments() {
	for _, info := range mrg.mergedFragments {
		if err := info.CheckLanguages(); err != nil {
			mrg.errorList.Add(err)
		}
	}
}

// PublishMergedFragments uploads the merged fragments to GCS if appropriate.
func (mrg *Merger) PublishMergedFragments() {
	if strings.HasPrefix(mrg.mergedLocation, gcs.BucketPrefix) {
		mrg.transferWithGCS(mrg.mergedDirectory, mrg.mergedLocation)
	}
}

// transferWithGCS transfers 'src' to 'dst' using mrg.gcs. Either of
// the two paths may be a GCS location. The output is logged, and any
// errors are accumulated and are retrievable via Error().
func (mrg *Merger) transferWithGCS(src, dst string) {
	output, err := mrg.gcs.TransferTree(src, dst)
	if err != nil {
		mrg.errorList.Add(err)
	}
	log.Printf("transferWithGCS(%q, %q):\n%s", src, dst, output)
}

// Error returns any errors accumulated thus far by 'mrg'.
func (mrg *Merger) Error() error {
	return mrg.errorList.Error()
}

{
  "kind": "discovery#restDescription",
  "revision": "20211108",
  "basePath": "",
  "protocol": "rest",
  "rootUrl": "https://transcoder.googleapis.com/",
  "discoveryVersion": "v1",
  "ownerName": "Google",
  "id": "transcoder:v1",
  "description": "This API converts video files into formats suitable for consumer distribution. ",
  "servicePath": "",
  "ownerDomain": "google.com",
  "canonicalName": "Transcoder",
  "name": "transcoder",
  "mtlsRootUrl": "https://transcoder.mtls.googleapis.com/",
  "resources": {
    "projects": {
      "resources": {
        "locations": {
          "resources": {
            "jobs": {
              "methods": {
                "delete": {
                  "description": "Deletes a job.",
                  "path": "v1/{+name}",
                  "httpMethod": "DELETE",
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobs/{jobsId}",
                  "response": {
                    "$ref": "Empty"
                  },
                  "id": "transcoder.projects.locations.jobs.delete",
                  "parameterOrder": [
                    "name"
                  ],
                  "parameters": {
                    "name": {
                      "type": "string",
                      "description": "Required. The name of the job to delete. Format: `projects/{project}/locations/{location}/jobs/{job}`",
                      "pattern": "^projects/[^/]+/locations/[^/]+/jobs/[^/]+$",
                      "location": "path",
                      "required": true
                    },
                    "allowMissing": {
                      "location": "query",
                      "type": "boolean",
                      "description": "If set to true, and the job is not found, the request will succeed but no action will be taken on the server."
                    }
                  }
                },
                "list": {
                  "path": "v1/{+parent}/jobs",
                  "description": "Lists jobs in the specified region.",
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobs",
                  "parameterOrder": [
                    "parent"
                  ],
                  "parameters": {
                    "pageToken": {
                      "location": "query",
                      "type": "string",
                      "description": "The `next_page_token` value returned from a previous List request, if any."
                    },
                    "parent": {
                      "required": true,
                      "description": "Required. Format: `projects/{project}/locations/{location}`",
                      "type": "string",
                      "location": "path",
                      "pattern": "^projects/[^/]+/locations/[^/]+$"
                    },
                    "filter": {
                      "description": "The filter expression, following the syntax outlined in https://google.aip.dev/160.",
                      "location": "query",
                      "type": "string"
                    },
                    "orderBy": {
                      "description": "One or more fields to compare and use to sort the output. See https://google.aip.dev/132#ordering.",
                      "location": "query",
                      "type": "string"
                    },
                    "pageSize": {
                      "format": "int32",
                      "type": "integer",
                      "description": "The maximum number of items to return.",
                      "location": "query"
                    }
                  },
                  "id": "transcoder.projects.locations.jobs.list",
                  "httpMethod": "GET",
                  "response": {
                    "$ref": "ListJobsResponse"
                  }
                },
                "create": {
                  "description": "Creates a job in the specified region.",
                  "httpMethod": "POST",
                  "request": {
                    "$ref": "Job"
                  },
                  "parameterOrder": [
                    "parent"
                  ],
                  "path": "v1/{+parent}/jobs",
                  "id": "transcoder.projects.locations.jobs.create",
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobs",
                  "parameters": {
                    "parent": {
                      "location": "path",
                      "pattern": "^projects/[^/]+/locations/[^/]+$",
                      "description": "Required. The parent location to create and process this job. Format: `projects/{project}/locations/{location}`",
                      "required": true,
                      "type": "string"
                    }
                  },
                  "response": {
                    "$ref": "Job"
                  }
                },
                "get": {
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobs/{jobsId}",
                  "path": "v1/{+name}",
                  "id": "transcoder.projects.locations.jobs.get",
                  "description": "Returns the job data.",
                  "response": {
                    "$ref": "Job"
                  },
                  "parameterOrder": [
                    "name"
                  ],
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "parameters": {
                    "name": {
                      "pattern": "^projects/[^/]+/locations/[^/]+/jobs/[^/]+$",
                      "description": "Required. The name of the job to retrieve. Format: `projects/{project}/locations/{location}/jobs/{job}`",
                      "location": "path",
                      "required": true,
                      "type": "string"
                    }
                  },
                  "httpMethod": "GET"
                }
              }
            },
            "jobTemplates": {
              "methods": {
                "create": {
                  "path": "v1/{+parent}/jobTemplates",
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobTemplates",
                  "httpMethod": "POST",
                  "request": {
                    "$ref": "JobTemplate"
                  },
                  "response": {
                    "$ref": "JobTemplate"
                  },
                  "description": "Creates a job template in the specified region.",
                  "parameters": {
                    "parent": {
                      "type": "string",
                      "pattern": "^projects/[^/]+/locations/[^/]+$",
                      "required": true,
                      "description": "Required. The parent location to create this job template. Format: `projects/{project}/locations/{location}`",
                      "location": "path"
                    },
                    "jobTemplateId": {
                      "type": "string",
                      "description": "Required. The ID to use for the job template, which will become the final component of the job template's resource name. This value should be 4-63 characters, and valid characters must match the regular expression `a-zA-Z*`.",
                      "location": "query"
                    }
                  },
                  "parameterOrder": [
                    "parent"
                  ],
                  "id": "transcoder.projects.locations.jobTemplates.create"
                },
                "get": {
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobTemplates/{jobTemplatesId}",
                  "id": "transcoder.projects.locations.jobTemplates.get",
                  "httpMethod": "GET",
                  "description": "Returns the job template data.",
                  "parameters": {
                    "name": {
                      "pattern": "^projects/[^/]+/locations/[^/]+/jobTemplates/[^/]+$",
                      "description": "Required. The name of the job template to retrieve. Format: `projects/{project}/locations/{location}/jobTemplates/{job_template}`",
                      "required": true,
                      "type": "string",
                      "location": "path"
                    }
                  },
                  "response": {
                    "$ref": "JobTemplate"
                  },
                  "parameterOrder": [
                    "name"
                  ],
                  "path": "v1/{+name}"
                },
                "delete": {
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "description": "Deletes a job template.",
                  "path": "v1/{+name}",
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobTemplates/{jobTemplatesId}",
                  "response": {
                    "$ref": "Empty"
                  },
                  "parameters": {
                    "allowMissing": {
                      "location": "query",
                      "type": "boolean",
                      "description": "If set to true, and the job template is not found, the request will succeed but no action will be taken on the server."
                    },
                    "name": {
                      "type": "string",
                      "description": "Required. The name of the job template to delete. `projects/{project}/locations/{location}/jobTemplates/{job_template}`",
                      "pattern": "^projects/[^/]+/locations/[^/]+/jobTemplates/[^/]+$",
                      "required": true,
                      "location": "path"
                    }
                  },
                  "parameterOrder": [
                    "name"
                  ],
                  "httpMethod": "DELETE",
                  "id": "transcoder.projects.locations.jobTemplates.delete"
                },
                "list": {
                  "parameters": {
                    "orderBy": {
                      "location": "query",
                      "description": "One or more fields to compare and use to sort the output. See https://google.aip.dev/132#ordering.",
                      "type": "string"
                    },
                    "filter": {
                      "location": "query",
                      "description": "The filter expression, following the syntax outlined in https://google.aip.dev/160.",
                      "type": "string"
                    },
                    "pageToken": {
                      "location": "query",
                      "type": "string",
                      "description": "The `next_page_token` value returned from a previous List request, if any."
                    },
                    "pageSize": {
                      "type": "integer",
                      "location": "query",
                      "format": "int32",
                      "description": "The maximum number of items to return."
                    },
                    "parent": {
                      "type": "string",
                      "description": "Required. The parent location from which to retrieve the collection of job templates. Format: `projects/{project}/locations/{location}`",
                      "required": true,
                      "pattern": "^projects/[^/]+/locations/[^/]+$",
                      "location": "path"
                    }
                  },
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform"
                  ],
                  "path": "v1/{+parent}/jobTemplates",
                  "description": "Lists job templates in the specified region.",
                  "response": {
                    "$ref": "ListJobTemplatesResponse"
                  },
                  "flatPath": "v1/projects/{projectsId}/locations/{locationsId}/jobTemplates",
                  "parameterOrder": [
                    "parent"
                  ],
                  "httpMethod": "GET",
                  "id": "transcoder.projects.locations.jobTemplates.list"
                }
              }
            }
          }
        }
      }
    }
  },
  "documentationLink": "https://cloud.google.com/transcoder/docs/",
  "batchPath": "batch",
  "auth": {
    "oauth2": {
      "scopes": {
        "https://www.googleapis.com/auth/cloud-platform": {
          "description": "See, edit, configure, and delete your Google Cloud data and see the email address for your Google Account."
        }
      }
    }
  },
  "icons": {
    "x32": "http://www.google.com/images/icons/product/search-32.gif",
    "x16": "http://www.google.com/images/icons/product/search-16.gif"
  },
  "schemas": {
    "VideoStream": {
      "properties": {
        "h265": {
          "description": "H265 codec settings.",
          "$ref": "H265CodecSettings"
        },
        "h264": {
          "description": "H264 codec settings.",
          "$ref": "H264CodecSettings"
        },
        "vp9": {
          "description": "VP9 codec settings.",
          "$ref": "Vp9CodecSettings"
        }
      },
      "type": "object",
      "description": "Video stream resource.",
      "id": "VideoStream"
    },
    "AnimationEnd": {
      "id": "AnimationEnd",
      "description": "End previous overlay animation from the video. Without AnimationEnd, the overlay object will keep the state of previous animation until the end of the video.",
      "type": "object",
      "properties": {
        "startTimeOffset": {
          "format": "google-duration",
          "description": "The time to end overlay object, in seconds. Default: 0",
          "type": "string"
        }
      }
    },
    "PreprocessingConfig": {
      "properties": {
        "audio": {
          "description": "Audio preprocessing configuration.",
          "$ref": "Audio"
        },
        "deblock": {
          "description": "Deblock preprocessing configuration.",
          "$ref": "Deblock"
        },
        "pad": {
          "description": "Specify the video pad filter configuration.",
          "$ref": "Pad"
        },
        "crop": {
          "$ref": "Crop",
          "description": "Specify the video cropping configuration."
        },
        "denoise": {
          "$ref": "Denoise",
          "description": "Denoise preprocessing configuration."
        },
        "color": {
          "description": "Color preprocessing configuration.",
          "$ref": "Color"
        }
      },
      "description": "Preprocessing configurations.",
      "id": "PreprocessingConfig",
      "type": "object"
    },
    "Animation": {
      "description": "Animation types.",
      "type": "object",
      "id": "Animation",
      "properties": {
        "animationStatic": {
          "description": "Display static overlay object.",
          "$ref": "AnimationStatic"
        },
        "animationEnd": {
          "$ref": "AnimationEnd",
          "description": "End previous animation."
        },
        "animationFade": {
          "description": "Display overlay object with fade animation.",
          "$ref": "AnimationFade"
        }
      }
    },
    "Image": {
      "description": "Overlaid jpeg image.",
      "properties": {
        "alpha": {
          "description": "Target image opacity. Valid values are from `1.0` (solid, default) to `0.0` (transparent), exclusive. Set this to a value greater than `0.0`.",
          "type": "number",
          "format": "double"
        },
        "uri": {
          "description": "Required. URI of the JPEG image in Cloud Storage. For example, `gs://bucket/inputs/image.jpeg`. JPEG is the only supported image type.",
          "type": "string"
        },
        "resolution": {
          "$ref": "NormalizedCoordinate",
          "description": "Normalized image resolution, based on output video resolution. Valid values: `0.0`–`1.0`. To respect the original image aspect ratio, set either `x` or `y` to `0.0`. To use the original image resolution, set both `x` and `y` to `0.0`."
        }
      },
      "id": "Image",
      "type": "object"
    },
    "EditAtom": {
      "description": "Edit atom.",
      "type": "object",
      "id": "EditAtom",
      "properties": {
        "inputs": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "List of `Input.key`s identifying files that should be used in this atom. The listed `inputs` must have the same timeline."
        },
        "endTimeOffset": {
          "type": "string",
          "format": "google-duration",
          "description": "End time in seconds for the atom, relative to the input file timeline. When `end_time_offset` is not specified, the `inputs` are used until the end of the atom."
        },
        "startTimeOffset": {
          "format": "google-duration",
          "description": "Start time in seconds for the atom, relative to the input file timeline. The default is `0s`.",
          "type": "string"
        },
        "key": {
          "type": "string",
          "description": "A unique key for this atom. Must be specified when using advanced mapping."
        }
      }
    },
    "NormalizedCoordinate": {
      "description": "2D normalized coordinates. Default: `{0.0, 0.0}`",
      "properties": {
        "x": {
          "description": "Normalized x coordinate.",
          "format": "double",
          "type": "number"
        },
        "y": {
          "type": "number",
          "format": "double",
          "description": "Normalized y coordinate."
        }
      },
      "id": "NormalizedCoordinate",
      "type": "object"
    },
    "Input": {
      "type": "object",
      "description": "Input asset.",
      "properties": {
        "key": {
          "type": "string",
          "description": "A unique key for this input. Must be specified when using advanced mapping and edit lists."
        },
        "uri": {
          "description": "URI of the media. Input files must be at least 5 seconds in duration and stored in Cloud Storage (for example, `gs://bucket/inputs/file.mp4`). If empty, the value will be populated from `Job.input_uri`.",
          "type": "string"
        },
        "preprocessingConfig": {
          "$ref": "PreprocessingConfig",
          "description": "Preprocessing configurations."
        }
      },
      "id": "Input"
    },
    "AdBreak": {
      "type": "object",
      "id": "AdBreak",
      "properties": {
        "startTimeOffset": {
          "type": "string",
          "description": "Start time in seconds for the ad break, relative to the output file timeline. The default is `0s`.",
          "format": "google-duration"
        }
      },
      "description": "Ad break."
    },
    "Deblock": {
      "id": "Deblock",
      "type": "object",
      "properties": {
        "enabled": {
          "description": "Enable deblocker. The default is `false`.",
          "type": "boolean"
        },
        "strength": {
          "description": "Set strength of the deblocker. Enter a value between 0 and 1. The higher the value, the stronger the block removal. 0 is no deblocking. The default is 0.",
          "type": "number",
          "format": "double"
        }
      },
      "description": "Deblock preprocessing configuration."
    },
    "AudioStream": {
      "description": "Audio stream resource.",
      "properties": {
        "sampleRateHertz": {
          "format": "int32",
          "type": "integer",
          "description": "The audio sample rate in Hertz. The default is 48000 Hertz."
        },
        "codec": {
          "type": "string",
          "description": "The codec for this audio stream. The default is `aac`. Supported audio codecs: - `aac` - `aac-he` - `aac-he-v2` - `mp3` - `ac3` - `eac3`"
        },
        "channelCount": {
          "format": "int32",
          "description": "Number of audio channels. Must be between 1 and 6. The default is 2.",
          "type": "integer"
        },
        "channelLayout": {
          "description": "A list of channel names specifying layout of the audio channels. This only affects the metadata embedded in the container headers, if supported by the specified format. The default is `[\"fl\", \"fr\"]`. Supported channel names: - `fl` - Front left channel - `fr` - Front right channel - `sl` - Side left channel - `sr` - Side right channel - `fc` - Front center channel - `lfe` - Low frequency",
          "type": "array",
          "items": {
            "type": "string"
          }
        },
        "bitrateBps": {
          "type": "integer",
          "format": "int32",
          "description": "Required. Audio bitrate in bits per second. Must be between 1 and 10,000,000."
        },
        "mapping": {
          "type": "array",
          "items": {
            "$ref": "AudioMapping"
          },
          "description": "The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`."
        }
      },
      "type": "object",
      "id": "AudioStream"
    },
    "ListJobsResponse": {
      "type": "object",
      "description": "Response message for `TranscoderService.ListJobs`.",
      "id": "ListJobsResponse",
      "properties": {
        "nextPageToken": {
          "description": "The pagination token.",
          "type": "string"
        },
        "unreachable": {
          "type": "array",
          "description": "List of regions that could not be reached.",
          "items": {
            "type": "string"
          }
        },
        "jobs": {
          "description": "List of jobs in the specified region.",
          "items": {
            "$ref": "Job"
          },
          "type": "array"
        }
      }
    },
    "Status": {
      "type": "object",
      "description": "The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).",
      "id": "Status",
      "properties": {
        "code": {
          "format": "int32",
          "type": "integer",
          "description": "The status code, which should be an enum value of google.rpc.Code."
        },
        "message": {
          "type": "string",
          "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client."
        },
        "details": {
          "items": {
            "additionalProperties": {
              "description": "Properties of the object. Contains field @type with type URL.",
              "type": "any"
            },
            "type": "object"
          },
          "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use.",
          "type": "array"
        }
      }
    },
    "JobConfig": {
      "type": "object",
      "id": "JobConfig",
      "description": "Job configuration",
      "properties": {
        "spriteSheets": {
          "items": {
            "$ref": "SpriteSheet"
          },
          "type": "array",
          "description": "List of output sprite sheets."
        },
        "output": {
          "$ref": "Output",
          "description": "Output configuration."
        },
        "editList": {
          "description": "List of `Edit atom`s. Defines the ultimate timeline of the resulting file or manifest.",
          "type": "array",
          "items": {
            "$ref": "EditAtom"
          }
        },
        "inputs": {
          "type": "array",
          "description": "List of input assets stored in Cloud Storage.",
          "items": {
            "$ref": "Input"
          }
        },
        "adBreaks": {
          "description": "List of ad breaks. Specifies where to insert ad break tags in the output manifests.",
          "type": "array",
          "items": {
            "$ref": "AdBreak"
          }
        },
        "pubsubDestination": {
          "description": "Destination on Pub/Sub.",
          "$ref": "PubsubDestination"
        },
        "manifests": {
          "type": "array",
          "items": {
            "$ref": "Manifest"
          },
          "description": "List of output manifests."
        },
        "muxStreams": {
          "type": "array",
          "items": {
            "$ref": "MuxStream"
          },
          "description": "List of multiplexing settings for output streams."
        },
        "overlays": {
          "items": {
            "$ref": "Overlay"
          },
          "type": "array",
          "description": "List of overlays on the output video, in descending Z-order."
        },
        "elementaryStreams": {
          "type": "array",
          "items": {
            "$ref": "ElementaryStream"
          },
          "description": "List of elementary streams."
        }
      }
    },
    "AnimationStatic": {
      "type": "object",
      "properties": {
        "startTimeOffset": {
          "format": "google-duration",
          "type": "string",
          "description": "The time to start displaying the overlay object, in seconds. Default: 0"
        },
        "xy": {
          "$ref": "NormalizedCoordinate",
          "description": "Normalized coordinates based on output video resolution. Valid values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay object. For example, use the x and y coordinates {0,0} to position the top-left corner of the overlay animation in the top-left corner of the output video."
        }
      },
      "description": "Display static overlay object.",
      "id": "AnimationStatic"
    },
    "Output": {
      "id": "Output",
      "type": "object",
      "description": "Location of output file(s) in a Cloud Storage bucket.",
      "properties": {
        "uri": {
          "description": "URI for the output file(s). For example, `gs://my-bucket/outputs/`. If empty the value is populated from `Job.output_uri`.",
          "type": "string"
        }
      }
    },
    "JobTemplate": {
      "description": "Transcoding job template resource.",
      "properties": {
        "config": {
          "description": "The configuration for this template.",
          "$ref": "JobConfig"
        },
        "name": {
          "description": "The resource name of the job template. Format: `projects/{project_number}/locations/{location}/jobTemplates/{job_template}`",
          "type": "string"
        }
      },
      "type": "object",
      "id": "JobTemplate"
    },
    "Overlay": {
      "type": "object",
      "description": "Overlay configuration.",
      "id": "Overlay",
      "properties": {
        "animations": {
          "items": {
            "$ref": "Animation"
          },
          "description": "List of Animations. The list should be chronological, without any time overlap.",
          "type": "array"
        },
        "image": {
          "$ref": "Image",
          "description": "Image overlay."
        }
      }
    },
    "SegmentSettings": {
      "properties": {
        "segmentDuration": {
          "description": "Duration of the segments in seconds. The default is `6.0s`. Note that `segmentDuration` must be greater than or equal to [`gopDuration`](#videostream), and `segmentDuration` must be divisible by [`gopDuration`](#videostream).",
          "type": "string",
          "format": "google-duration"
        },
        "individualSegments": {
          "type": "boolean",
          "description": "Required. Create an individual segment file. The default is `false`."
        }
      },
      "id": "SegmentSettings",
      "description": "Segment settings for `ts`, `fmp4` and `vtt`.",
      "type": "object"
    },
    "PubsubDestination": {
      "id": "PubsubDestination",
      "properties": {
        "topic": {
          "type": "string",
          "description": "The name of the Pub/Sub topic to publish job completion notification to. For example: `projects/{project}/topics/{topic}`."
        }
      },
      "type": "object",
      "description": "A Pub/Sub destination."
    },
    "Denoise": {
      "properties": {
        "tune": {
          "type": "string",
          "description": "Set the denoiser mode. The default is `standard`. Supported denoiser modes: - `standard` - `grain`"
        },
        "strength": {
          "type": "number",
          "format": "double",
          "description": "Set strength of the denoise. Enter a value between 0 and 1. The higher the value, the smoother the image. 0 is no denoising. The default is 0."
        }
      },
      "type": "object",
      "description": "Denoise preprocessing configuration.",
      "id": "Denoise"
    },
    "TextMapping": {
      "properties": {
        "atomKey": {
          "type": "string",
          "description": "Required. The `EditAtom.key` that references atom with text inputs in the `Job.edit_list`."
        },
        "inputTrack": {
          "format": "int32",
          "description": "Required. The zero-based index of the track in the input file.",
          "type": "integer"
        },
        "inputKey": {
          "type": "string",
          "description": "Required. The `Input.key` that identifies the input file."
        }
      },
      "id": "TextMapping",
      "type": "object",
      "description": "The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`."
    },
    "Audio": {
      "description": "Audio preprocessing configuration.",
      "properties": {
        "lufs": {
          "type": "number",
          "description": "Specify audio loudness normalization in loudness units relative to full scale (LUFS). Enter a value between -24 and 0 (the default), where: * -24 is the Advanced Television Systems Committee (ATSC A/85) standard * -23 is the EU R128 broadcast standard * -19 is the prior standard for online mono audio * -18 is the ReplayGain standard * -16 is the prior standard for stereo audio * -14 is the new online audio standard recommended by Spotify, as well as Amazon Echo * 0 disables normalization",
          "format": "double"
        },
        "lowBoost": {
          "type": "boolean",
          "description": "Enable boosting low frequency components. The default is `false`."
        },
        "highBoost": {
          "type": "boolean",
          "description": "Enable boosting high frequency components. The default is `false`."
        }
      },
      "type": "object",
      "id": "Audio"
    },
    "SpriteSheet": {
      "properties": {
        "spriteWidthPixels": {
          "description": "Required. The width of sprite in pixels. Must be an even integer. To preserve the source aspect ratio, set the SpriteSheet.sprite_width_pixels field or the SpriteSheet.sprite_height_pixels field, but not both (the API will automatically calculate the missing field).",
          "format": "int32",
          "type": "integer"
        },
        "totalCount": {
          "description": "Total number of sprites. Create the specified number of sprites distributed evenly across the timeline of the output media. The default is 100.",
          "format": "int32",
          "type": "integer"
        },
        "interval": {
          "description": "Starting from `0s`, create sprites at regular intervals. Specify the interval value in seconds.",
          "type": "string",
          "format": "google-duration"
        },
        "startTimeOffset": {
          "format": "google-duration",
          "description": "Start time in seconds, relative to the output file timeline. Determines the first sprite to pick. The default is `0s`.",
          "type": "string"
        },
        "filePrefix": {
          "type": "string",
          "description": "Required. File name prefix for the generated sprite sheets. Each sprite sheet has an incremental 10-digit zero-padded suffix starting from 0 before the extension, such as `sprite_sheet0000000123.jpeg`."
        },
        "rowCount": {
          "description": "The maximum number of rows per sprite sheet. When the sprite sheet is full, a new sprite sheet is created. The default is 0, which indicates no maximum limit.",
          "format": "int32",
          "type": "integer"
        },
        "format": {
          "description": "Format type. The default is `jpeg`. Supported formats: - `jpeg`",
          "type": "string"
        },
        "columnCount": {
          "format": "int32",
          "type": "integer",
          "description": "The maximum number of sprites per row in a sprite sheet. The default is 0, which indicates no maximum limit."
        },
        "quality": {
          "description": "The quality of the generated sprite sheet. Enter a value between 1 and 100, where 1 is the lowest quality and 100 is the highest quality. The default is 100. A high quality value corresponds to a low image data compression ratio.",
          "format": "int32",
          "type": "integer"
        },
        "endTimeOffset": {
          "format": "google-duration",
          "description": "End time in seconds, relative to the output file timeline. When `end_time_offset` is not specified, the sprites are generated until the end of the output file.",
          "type": "string"
        },
        "spriteHeightPixels": {
          "type": "integer",
          "description": "Required. The height of sprite in pixels. Must be an even integer. To preserve the source aspect ratio, set the SpriteSheet.sprite_height_pixels field or the SpriteSheet.sprite_width_pixels field, but not both (the API will automatically calculate the missing field).",
          "format": "int32"
        }
      },
      "id": "SpriteSheet",
      "description": "Sprite sheet configuration.",
      "type": "object"
    },
    "AudioMapping": {
      "description": "The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`.",
      "type": "object",
      "id": "AudioMapping",
      "properties": {
        "outputChannel": {
          "format": "int32",
          "description": "Required. The zero-based index of the channel in the output audio stream.",
          "type": "integer"
        },
        "inputChannel": {
          "format": "int32",
          "type": "integer",
          "description": "Required. The zero-based index of the channel in the input audio stream."
        },
        "atomKey": {
          "description": "Required. The `EditAtom.key` that references the atom with audio inputs in the `Job.edit_list`.",
          "type": "string"
        },
        "gainDb": {
          "description": "Audio volume control in dB. Negative values decrease volume, positive values increase. The default is 0.",
          "type": "number",
          "format": "double"
        },
        "inputKey": {
          "description": "Required. The `Input.key` that identifies the input file.",
          "type": "string"
        },
        "inputTrack": {
          "description": "Required. The zero-based index of the track in the input file.",
          "type": "integer",
          "format": "int32"
        }
      }
    },
    "H264CodecSettings": {
      "properties": {
        "tune": {
          "type": "string",
          "description": "Enforces the specified codec tune. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune). Note that certain values for this field may cause the transcoder to override other fields you set in the `H264CodecSettings` message."
        },
        "entropyCoder": {
          "type": "string",
          "description": "The entropy coder to use. The default is `cabac`. Supported entropy coders: - `cavlc` - `cabac`"
        },
        "crfLevel": {
          "format": "int32",
          "description": "Target CRF level. Must be between 10 and 36, where 10 is the highest quality and 36 is the most efficient compression. The default is 21.",
          "type": "integer"
        },
        "pixelFormat": {
          "type": "string",
          "description": "Pixel format to use. The default is `yuv420p`. Supported pixel formats: - `yuv420p` pixel format - `yuv422p` pixel format - `yuv444p` pixel format - `yuv420p10` 10-bit HDR pixel format - `yuv422p10` 10-bit HDR pixel format - `yuv444p10` 10-bit HDR pixel format - `yuv420p12` 12-bit HDR pixel format - `yuv422p12` 12-bit HDR pixel format - `yuv444p12` 12-bit HDR pixel format"
        },
        "vbvSizeBits": {
          "description": "Size of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to `VideoStream.bitrate_bps`.",
          "type": "integer",
          "format": "int32"
        },
        "enableTwoPass": {
          "description": "Use two-pass encoding strategy to achieve better video quality. `VideoStream.rate_control_mode` must be `vbr`. The default is `false`.",
          "type": "boolean"
        },
        "heightPixels": {
          "type": "integer",
          "description": "The height of the video in pixels. Must be an even integer. When not specified, the height is adjusted to match the specified width and input aspect ratio. If both are omitted, the input height is used.",
          "format": "int32"
        },
        "gopDuration": {
          "description": "Select the GOP size based on the specified duration. The default is `3s`. Note that `gopDuration` must be less than or equal to [`segmentDuration`](#SegmentSettings), and [`segmentDuration`](#SegmentSettings) must be divisible by `gopDuration`.",
          "format": "google-duration",
          "type": "string"
        },
        "frameRate": {
          "description": "Required. The target video frame rate in frames per second (FPS). Must be less than or equal to 120. Will default to the input frame rate if larger than the input frame rate. The API will generate an output FPS that is divisible by the input FPS, and smaller or equal to the target FPS. See [Calculating frame rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for more information.",
          "format": "double",
          "type": "number"
        },
        "gopFrameCount": {
          "type": "integer",
          "description": "Select the GOP size based on the specified frame count. Must be greater than zero.",
          "format": "int32"
        },
        "widthPixels": {
          "description": "The width of the video in pixels. Must be an even integer. When not specified, the width is adjusted to match the specified height and input aspect ratio. If both are omitted, the input width is used.",
          "type": "integer",
          "format": "int32"
        },
        "bPyramid": {
          "description": "Allow B-pyramid for reference frame selection. This may not be supported on all decoders. The default is `false`.",
          "type": "boolean"
        },
        "preset": {
          "description": "Enforces the specified codec preset. The default is `veryfast`. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Preset). Note that certain values for this field may cause the transcoder to override other fields you set in the `H264CodecSettings` message.",
          "type": "string"
        },
        "bFrameCount": {
          "format": "int32",
          "description": "The number of consecutive B-frames. Must be greater than or equal to zero. Must be less than `VideoStream.gop_frame_count` if set. The default is 0.",
          "type": "integer"
        },
        "vbvFullnessBits": {
          "description": "Initial fullness of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to 90% of `VideoStream.vbv_size_bits`.",
          "type": "integer",
          "format": "int32"
        },
        "rateControlMode": {
          "description": "Specify the `rate_control_mode`. The default is `vbr`. Supported rate control modes: - `vbr` - variable bitrate - `crf` - constant rate factor",
          "type": "string"
        },
        "aqStrength": {
          "description": "Specify the intensity of the adaptive quantizer (AQ). Must be between 0 and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A higher value equals a lower bitrate but smoother image. The default is 0.",
          "format": "double",
          "type": "number"
        },
        "allowOpenGop": {
          "description": "Specifies whether an open Group of Pictures (GOP) structure should be allowed or not. The default is `false`.",
          "type": "boolean"
        },
        "profile": {
          "type": "string",
          "description": "Enforces the specified codec profile. The following profiles are supported: * `baseline` * `main` * `high` (default) The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune). Note that certain values for this field may cause the transcoder to override other fields you set in the `H264CodecSettings` message."
        },
        "bitrateBps": {
          "type": "integer",
          "format": "int32",
          "description": "Required. The video bitrate in bits per second. The minimum value is 1,000. The maximum value is 800,000,000."
        }
      },
      "type": "object",
      "description": "H264 codec settings.",
      "id": "H264CodecSettings"
    },
    "H265CodecSettings": {
      "description": "H265 codec settings.",
      "properties": {
        "profile": {
          "description": "Enforces the specified codec profile. The following profiles are supported: * 8-bit profiles * `main` (default) * `main-intra` * `mainstillpicture` * 10-bit profiles * `main10` (default) * `main10-intra` * `main422-10` * `main422-10-intra` * `main444-10` * `main444-10-intra` * 12-bit profiles * `main12` (default) * `main12-intra` * `main422-12` * `main422-12-intra` * `main444-12` * `main444-12-intra` The available options are [FFmpeg-compatible](https://x265.readthedocs.io/). Note that certain values for this field may cause the transcoder to override other fields you set in the `H265CodecSettings` message.",
          "type": "string"
        },
        "bitrateBps": {
          "format": "int32",
          "type": "integer",
          "description": "Required. The video bitrate in bits per second. The minimum value is 1,000. The maximum value is 800,000,000."
        },
        "frameRate": {
          "type": "number",
          "description": "Required. The target video frame rate in frames per second (FPS). Must be less than or equal to 120. Will default to the input frame rate if larger than the input frame rate. The API will generate an output FPS that is divisible by the input FPS, and smaller or equal to the target FPS. See [Calculating frame rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for more information.",
          "format": "double"
        },
        "vbvSizeBits": {
          "type": "integer",
          "format": "int32",
          "description": "Size of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to `VideoStream.bitrate_bps`."
        },
        "rateControlMode": {
          "description": "Specify the `rate_control_mode`. The default is `vbr`. Supported rate control modes: - `vbr` - variable bitrate - `crf` - constant rate factor",
          "type": "string"
        },
        "preset": {
          "type": "string",
          "description": "Enforces the specified codec preset. The default is `veryfast`. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265). Note that certain values for this field may cause the transcoder to override other fields you set in the `H265CodecSettings` message."
        },
        "heightPixels": {
          "type": "integer",
          "format": "int32",
          "description": "The height of the video in pixels. Must be an even integer. When not specified, the height is adjusted to match the specified width and input aspect ratio. If both are omitted, the input height is used."
        },
        "aqStrength": {
          "type": "number",
          "format": "double",
          "description": "Specify the intensity of the adaptive quantizer (AQ). Must be between 0 and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A higher value equals a lower bitrate but smoother image. The default is 0."
        },
        "bFrameCount": {
          "type": "integer",
          "format": "int32",
          "description": "The number of consecutive B-frames. Must be greater than or equal to zero. Must be less than `VideoStream.gop_frame_count` if set. The default is 0."
        },
        "widthPixels": {
          "format": "int32",
          "type": "integer",
          "description": "The width of the video in pixels. Must be an even integer. When not specified, the width is adjusted to match the specified height and input aspect ratio. If both are omitted, the input width is used."
        },
        "enableTwoPass": {
          "type": "boolean",
          "description": "Use two-pass encoding strategy to achieve better video quality. `VideoStream.rate_control_mode` must be `vbr`. The default is `false`."
        },
        "vbvFullnessBits": {
          "type": "integer",
          "description": "Initial fullness of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to 90% of `VideoStream.vbv_size_bits`.",
          "format": "int32"
        },
        "allowOpenGop": {
          "description": "Specifies whether an open Group of Pictures (GOP) structure should be allowed or not. The default is `false`.",
          "type": "boolean"
        },
        "gopFrameCount": {
          "description": "Select the GOP size based on the specified frame count. Must be greater than zero.",
          "type": "integer",
          "format": "int32"
        },
        "gopDuration": {
          "description": "Select the GOP size based on the specified duration. The default is `3s`. Note that `gopDuration` must be less than or equal to [`segmentDuration`](#SegmentSettings), and [`segmentDuration`](#SegmentSettings) must be divisible by `gopDuration`.",
          "format": "google-duration",
          "type": "string"
        },
        "crfLevel": {
          "type": "integer",
          "description": "Target CRF level. Must be between 10 and 36, where 10 is the highest quality and 36 is the most efficient compression. The default is 21.",
          "format": "int32"
        },
        "pixelFormat": {
          "type": "string",
          "description": "Pixel format to use. The default is `yuv420p`. Supported pixel formats: - `yuv420p` pixel format - `yuv422p` pixel format - `yuv444p` pixel format - `yuv420p10` 10-bit HDR pixel format - `yuv422p10` 10-bit HDR pixel format - `yuv444p10` 10-bit HDR pixel format - `yuv420p12` 12-bit HDR pixel format - `yuv422p12` 12-bit HDR pixel format - `yuv444p12` 12-bit HDR pixel format"
        },
        "tune": {
          "description": "Enforces the specified codec tune. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265). Note that certain values for this field may cause the transcoder to override other fields you set in the `H265CodecSettings` message.",
          "type": "string"
        },
        "bPyramid": {
          "type": "boolean",
          "description": "Allow B-pyramid for reference frame selection. This may not be supported on all decoders. The default is `false`."
        }
      },
      "id": "H265CodecSettings",
      "type": "object"
    },
    "Job": {
      "type": "object",
      "properties": {
        "state": {
          "readOnly": true,
          "type": "string",
          "description": "Output only. The current state of the job.",
          "enumDescriptions": [
            "The processing state is not specified.",
            "The job is enqueued and will be picked up for processing soon.",
            "The job is being processed.",
            "The job has been completed successfully.",
            "The job has failed. For additional information, see `failure_reason` and `failure_details`"
          ],
          "enum": [
            "PROCESSING_STATE_UNSPECIFIED",
            "PENDING",
            "RUNNING",
            "SUCCEEDED",
            "FAILED"
          ]
        },
        "name": {
          "description": "The resource name of the job. Format: `projects/{project_number}/locations/{location}/jobs/{job}`",
          "type": "string"
        },
        "outputUri": {
          "description": "Input only. Specify the `output_uri` to populate an empty `Job.config.output.uri` or `JobTemplate.config.output.uri` when using template. URI for the output file(s). For example, `gs://my-bucket/outputs/`.",
          "type": "string"
        },
        "createTime": {
          "type": "string",
          "format": "google-datetime",
          "readOnly": true,
          "description": "Output only. The time the job was created."
        },
        "ttlAfterCompletionDays": {
          "format": "int32",
          "description": "Job time to live value in days, which will be effective after job completion. Job should be deleted automatically after the given TTL. Enter a value between 1 and 90. The default is 30.",
          "type": "integer"
        },
        "templateId": {
          "description": "Input only. Specify the `template_id` to use for populating `Job.config`. The default is `preset/web-hd`. Preset Transcoder templates: - `preset/{preset_id}` - User defined JobTemplate: `{job_template_id}`",
          "type": "string"
        },
        "endTime": {
          "type": "string",
          "description": "Output only. The time the transcoding finished.",
          "readOnly": true,
          "format": "google-datetime"
        },
        "config": {
          "description": "The configuration for this job.",
          "$ref": "JobConfig"
        },
        "startTime": {
          "type": "string",
          "description": "Output only. The time the transcoding started.",
          "readOnly": true,
          "format": "google-datetime"
        },
        "error": {
          "description": "Output only. An error object that describes the reason for the failure. This property is always present when `state` is `FAILED`.",
          "readOnly": true,
          "$ref": "Status"
        },
        "inputUri": {
          "type": "string",
          "description": "Input only. Specify the `input_uri` to populate empty `uri` fields in each element of `Job.config.inputs` or `JobTemplate.config.inputs` when using template. URI of the media. Input files must be at least 5 seconds in duration and stored in Cloud Storage (for example, `gs://bucket/inputs/file.mp4`)."
        }
      },
      "description": "Transcoding job resource.",
      "id": "Job"
    },
    "Empty": {
      "type": "object",
      "properties": {},
      "id": "Empty",
      "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`."
    },
    "Pad": {
      "properties": {
        "leftPixels": {
          "format": "int32",
          "type": "integer",
          "description": "The number of pixels to add to the left. The default is 0."
        },
        "bottomPixels": {
          "type": "integer",
          "format": "int32",
          "description": "The number of pixels to add to the bottom. The default is 0."
        },
        "rightPixels": {
          "type": "integer",
          "format": "int32",
          "description": "The number of pixels to add to the right. The default is 0."
        },
        "topPixels": {
          "description": "The number of pixels to add to the top. The default is 0.",
          "format": "int32",
          "type": "integer"
        }
      },
      "description": "Pad filter configuration for the input video. The padded input video is scaled after padding with black to match the output resolution.",
      "type": "object",
      "id": "Pad"
    },
    "Crop": {
      "type": "object",
      "description": "Video cropping configuration for the input video. The cropped input video is scaled to match the output resolution.",
      "properties": {
        "leftPixels": {
          "type": "integer",
          "description": "The number of pixels to crop from the left. The default is 0.",
          "format": "int32"
        },
        "topPixels": {
          "format": "int32",
          "description": "The number of pixels to crop from the top. The default is 0.",
          "type": "integer"
        },
        "bottomPixels": {
          "type": "integer",
          "format": "int32",
          "description": "The number of pixels to crop from the bottom. The default is 0."
        },
        "rightPixels": {
          "description": "The number of pixels to crop from the right. The default is 0.",
          "type": "integer",
          "format": "int32"
        }
      },
      "id": "Crop"
    },
    "ListJobTemplatesResponse": {
      "description": "Response message for `TranscoderService.ListJobTemplates`.",
      "properties": {
        "nextPageToken": {
          "description": "The pagination token.",
          "type": "string"
        },
        "jobTemplates": {
          "items": {
            "$ref": "JobTemplate"
          },
          "type": "array",
          "description": "List of job templates in the specified region."
        },
        "unreachable": {
          "description": "List of regions that could not be reached.",
          "items": {
            "type": "string"
          },
          "type": "array"
        }
      },
      "type": "object",
      "id": "ListJobTemplatesResponse"
    },
    "MuxStream": {
      "type": "object",
      "id": "MuxStream",
      "description": "Multiplexing settings for output stream.",
      "properties": {
        "key": {
          "description": "A unique key for this multiplexed stream. HLS media manifests will be named `MuxStream.key` with the `.m3u8` extension suffix.",
          "type": "string"
        },
        "container": {
          "type": "string",
          "description": "The container format. The default is `mp4` Supported container formats: - `ts` - `fmp4`- the corresponding file extension is `.m4s` - `mp4` - `vtt`"
        },
        "elementaryStreams": {
          "type": "array",
          "description": "List of `ElementaryStream.key`s multiplexed in this stream.",
          "items": {
            "type": "string"
          }
        },
        "segmentSettings": {
          "$ref": "SegmentSettings",
          "description": "Segment settings for `ts`, `fmp4` and `vtt`."
        },
        "fileName": {
          "type": "string",
          "description": "The name of the generated file. The default is `MuxStream.key` with the extension suffix corresponding to the `MuxStream.container`. Individual segments also have an incremental 10-digit zero-padded suffix starting from 0 before the extension, such as `mux_stream0000000123.ts`."
        }
      }
    },
    "Vp9CodecSettings": {
      "type": "object",
      "id": "Vp9CodecSettings",
      "description": "VP9 codec settings.",
      "properties": {
        "widthPixels": {
          "description": "The width of the video in pixels. Must be an even integer. When not specified, the width is adjusted to match the specified height and input aspect ratio. If both are omitted, the input width is used.",
          "type": "integer",
          "format": "int32"
        },
        "rateControlMode": {
          "description": "Specify the `rate_control_mode`. The default is `vbr`. Supported rate control modes: - `vbr` - variable bitrate - `crf` - constant rate factor",
          "type": "string"
        },
        "gopFrameCount": {
          "description": "Select the GOP size based on the specified frame count. Must be greater than zero.",
          "type": "integer",
          "format": "int32"
        },
        "gopDuration": {
          "type": "string",
          "format": "google-duration",
          "description": "Select the GOP size based on the specified duration. The default is `3s`. Note that `gopDuration` must be less than or equal to [`segmentDuration`](#SegmentSettings), and [`segmentDuration`](#SegmentSettings) must be divisible by `gopDuration`."
        },
        "heightPixels": {
          "type": "integer",
          "format": "int32",
          "description": "The height of the video in pixels. Must be an even integer. When not specified, the height is adjusted to match the specified width and input aspect ratio. If both are omitted, the input height is used."
        },
        "crfLevel": {
          "format": "int32",
          "type": "integer",
          "description": "Target CRF level. Must be between 10 and 36, where 10 is the highest quality and 36 is the most efficient compression. The default is 21."
        },
        "bitrateBps": {
          "description": "Required. The video bitrate in bits per second. The minimum value is 1,000. The maximum value is 480,000,000.",
          "format": "int32",
          "type": "integer"
        },
        "pixelFormat": {
          "description": "Pixel format to use. The default is `yuv420p`. Supported pixel formats: - `yuv420p` pixel format - `yuv422p` pixel format - `yuv444p` pixel format - `yuv420p10` 10-bit HDR pixel format - `yuv422p10` 10-bit HDR pixel format - `yuv444p10` 10-bit HDR pixel format - `yuv420p12` 12-bit HDR pixel format - `yuv422p12` 12-bit HDR pixel format - `yuv444p12` 12-bit HDR pixel format",
          "type": "string"
        },
        "profile": {
          "type": "string",
          "description": "Enforces the specified codec profile. The following profiles are supported: * `profile0` (default) * `profile1` * `profile2` * `profile3` The available options are [WebM-compatible](https://www.webmproject.org/vp9/profiles/). Note that certain values for this field may cause the transcoder to override other fields you set in the `Vp9CodecSettings` message."
        },
        "frameRate": {
          "type": "number",
          "description": "Required. The target video frame rate in frames per second (FPS). Must be less than or equal to 120. Will default to the input frame rate if larger than the input frame rate. The API will generate an output FPS that is divisible by the input FPS, and smaller or equal to the target FPS. See [Calculating frame rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for more information.",
          "format": "double"
        }
      }
    },
    "Manifest": {
      "id": "Manifest",
      "type": "object",
      "properties": {
        "type": {
          "enumDescriptions": [
            "The manifest type is not specified.",
            "Create `HLS` manifest. The corresponding file extension is `.m3u8`.",
            "Create `DASH` manifest. The corresponding file extension is `.mpd`."
          ],
          "enum": [
            "MANIFEST_TYPE_UNSPECIFIED",
            "HLS",
            "DASH"
          ],
          "description": "Required. Type of the manifest, can be `HLS` or `DASH`.",
          "type": "string"
        },
        "muxStreams": {
          "description": "Required. List of user given `MuxStream.key`s that should appear in this manifest. When `Manifest.type` is `HLS`, a media manifest with name `MuxStream.key` and `.m3u8` extension is generated for each element of the `Manifest.mux_streams`.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "fileName": {
          "type": "string",
          "description": "The name of the generated file. The default is `manifest` with the extension suffix corresponding to the `Manifest.type`."
        }
      },
      "description": "Manifest configuration."
    },
    "ElementaryStream": {
      "properties": {
        "audioStream": {
          "$ref": "AudioStream",
          "description": "Encoding of an audio stream."
        },
        "key": {
          "description": "A unique key for this elementary stream.",
          "type": "string"
        },
        "textStream": {
          "$ref": "TextStream",
          "description": "Encoding of a text stream. For example, closed captions or subtitles."
        },
        "videoStream": {
          "description": "Encoding of a video stream.",
          "$ref": "VideoStream"
        }
      },
      "id": "ElementaryStream",
      "description": "Encoding of an input file such as an audio, video, or text track. Elementary streams must be packaged before mapping and sharing between different output formats.",
      "type": "object"
    },
    "Color": {
      "id": "Color",
      "description": "Color preprocessing configuration.",
      "type": "object",
      "properties": {
        "saturation": {
          "type": "number",
          "description": "Control color saturation of the video. Enter a value between -1 and 1, where -1 is fully desaturated and 1 is maximum saturation. 0 is no change. The default is 0.",
          "format": "double"
        },
        "brightness": {
          "format": "double",
          "description": "Control brightness of the video. Enter a value between -1 and 1, where -1 is minimum brightness and 1 is maximum brightness. 0 is no change. The default is 0.",
          "type": "number"
        },
        "contrast": {
          "description": "Control black and white contrast of the video. Enter a value between -1 and 1, where -1 is minimum contrast and 1 is maximum contrast. 0 is no change. The default is 0.",
          "type": "number",
          "format": "double"
        }
      }
    },
    "AnimationFade": {
      "description": "Display overlay object with fade animation.",
      "type": "object",
      "properties": {
        "fadeType": {
          "enum": [
            "FADE_TYPE_UNSPECIFIED",
            "FADE_IN",
            "FADE_OUT"
          ],
          "description": "Required. Type of fade animation: `FADE_IN` or `FADE_OUT`.",
          "type": "string",
          "enumDescriptions": [
            "The fade type is not specified.",
            "Fade the overlay object into view.",
            "Fade the overlay object out of view."
          ]
        },
        "startTimeOffset": {
          "format": "google-duration",
          "type": "string",
          "description": "The time to start the fade animation, in seconds. Default: 0"
        },
        "endTimeOffset": {
          "format": "google-duration",
          "description": "The time to end the fade animation, in seconds. Default: `start_time_offset` + 1s",
          "type": "string"
        },
        "xy": {
          "$ref": "NormalizedCoordinate",
          "description": "Normalized coordinates based on output video resolution. Valid values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay object. For example, use the x and y coordinates {0,0} to position the top-left corner of the overlay animation in the top-left corner of the output video."
        }
      },
      "id": "AnimationFade"
    },
    "TextStream": {
      "properties": {
        "mapping": {
          "type": "array",
          "items": {
            "$ref": "TextMapping"
          },
          "description": "The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`."
        },
        "codec": {
          "type": "string",
          "description": "The codec for this text stream. The default is `webvtt`. Supported text codecs: - `srt` - `ttml` - `cea608` - `cea708` - `webvtt`"
        }
      },
      "type": "object",
      "id": "TextStream",
      "description": "Encoding of a text stream. For example, closed captions or subtitles."
    }
  },
  "title": "Transcoder API",
  "parameters": {
    "oauth_token": {
      "location": "query",
      "type": "string",
      "description": "OAuth 2.0 token for the current user."
    },
    "access_token": {
      "type": "string",
      "description": "OAuth access token.",
      "location": "query"
    },
    "fields": {
      "location": "query",
      "description": "Selector specifying which fields to include in a partial response.",
      "type": "string"
    },
    "alt": {
      "enum": [
        "json",
        "media",
        "proto"
      ],
      "default": "json",
      "enumDescriptions": [
        "Responses with Content-Type of application/json",
        "Media download with context-dependent Content-Type",
        "Responses with Content-Type of application/x-protobuf"
      ],
      "description": "Data format for response.",
      "type": "string",
      "location": "query"
    },
    "uploadType": {
      "location": "query",
      "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\").",
      "type": "string"
    },
    "$.xgafv": {
      "enumDescriptions": [
        "v1 error format",
        "v2 error format"
      ],
      "location": "query",
      "type": "string",
      "enum": [
        "1",
        "2"
      ],
      "description": "V1 error format."
    },
    "callback": {
      "description": "JSONP",
      "type": "string",
      "location": "query"
    },
    "prettyPrint": {
      "description": "Returns response with indentations and line breaks.",
      "type": "boolean",
      "default": "true",
      "location": "query"
    },
    "key": {
      "type": "string",
      "location": "query",
      "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
    },
    "quotaUser": {
      "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.",
      "location": "query",
      "type": "string"
    },
    "upload_protocol": {
      "type": "string",
      "location": "query",
      "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
    }
  },
  "fullyEncodeReservedExpansion": true,
  "version": "v1",
  "baseUrl": "https://transcoder.googleapis.com/",
  "version_module": true
}
